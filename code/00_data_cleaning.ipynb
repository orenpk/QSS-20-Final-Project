{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7f7f5e4-1e8a-4725-a27a-eeb113af5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73026ec0-c38a-4f13-b8bc-92e2781b3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def categorize_race(race):\n",
    "    categories = {\n",
    "        'White': ['White', 'American Indian or Alaska Native, White', 'Asian, White', 'Black or African American, White', 'Other: Middle Eastern', 'Unknown, not collected, White'],\n",
    "        'Black/African American': ['Black or African American', 'Black or African American, White'],\n",
    "        'Hispanic/Latinx': ['Other: Hispanic', 'Other: \"Hispanic\"', 'Other: Latino', 'Other: Guyanese', 'Other: Puerto Rican', 'Other: Latina', 'Other: hispanic', 'Other: Mexican'],\n",
    "        'Asian/Pacific Islander': ['Asian', 'Other: East Indian', 'Asian, White', 'Other: Filipino', 'Native Hawaiian or Other Pacific Islander', 'Other: Indian'],\n",
    "        'American Indian or Alaska Native': ['American Indian or Alaska Native', 'American Indian or Alaska Native, White'],\n",
    "    }\n",
    "\n",
    "    for category, labels in categories.items():\n",
    "        if race in labels:\n",
    "            return category\n",
    "    return 'Other/Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e2390c0-dcf6-485a-8912-6004306822b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sirs_demo = pd.read_excel('../data/Dartmouth Data Set- SIRS .xlsx', sheet_name = 'Demographics')\n",
    "sirs_abc = pd.read_excel('../data/Dartmouth Data Set- SIRS .xlsx', sheet_name = 'ABC Data')\n",
    "feis = pd.read_excel('../data/Dartmouth FEIS Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da3ea55e-e25b-49c8-97aa-7c8bf04f13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates\n",
    "sirs_start_date = sirs_demo['Date Enrolled in START'].min().strftime('%B %d, %Y')\n",
    "sirs_end_date = sirs_demo['Date Enrolled in START'].max().strftime('%B %d, %Y')\n",
    "\n",
    "sirs_abc_start_date = pd.to_datetime(sirs_abc['Date Reviewed'], errors='coerce').min().strftime('%B %d, %Y')\n",
    "sirs_abc_end_date = pd.to_datetime(sirs_abc['Date Reviewed'], errors='coerce').max().strftime('%B %d, %Y')\n",
    "\n",
    "feis_start_date = feis['Start Date'].min().strftime('%B %d, %Y')\n",
    "feis_end_date = feis['Start Date'].max().strftime('%B %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14bf64ff-4de1-4605-a009-bbc705c1040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive analysis table for data\n",
    "sirs_observations = sirs_demo.shape[0]\n",
    "\n",
    "sirs_abc_observations = sirs_abc.shape[0]\n",
    "\n",
    "feis_observations = feis.shape[0]\n",
    "\n",
    "\n",
    "descriptive_analysis = pd.DataFrame({\n",
    "    'Sheet Name': ['Aberrant Behavior Checklist (ABC)', 'Demographics', 'Family Experiences with Severe Mental Illness Scale (FEIS)'],\n",
    "    'Number of Observations': [sirs_abc_observations, sirs_observations, feis_observations],\n",
    "    'Date Range' : [sirs_abc_start_date + \" to \" + sirs_abc_end_date, sirs_start_date + \" to \" + sirs_end_date, feis_start_date + \" to \" + feis_end_date],\n",
    "    'Unit of Analysis': [\"Record of Mental Health Stability\", \"Individual START Participant\", \"Respondent Survey Response\"]\n",
    "})\n",
    "\n",
    "styled_total = descriptive_analysis.style.hide(axis='index')\\\n",
    "    .format(na_rep='-', precision=0)\\\n",
    "    .set_table_styles(\n",
    "        [{'selector': 'caption',\n",
    "          'props': [('color', 'black'),\n",
    "                    ('font-size', '16px'),\n",
    "                    ('text-align', 'center'),\n",
    "                    ('font-weight', 'bold')]},\n",
    "         {'selector': 'th',\n",
    "          'props': [('border', '1px solid black'),\n",
    "                    ('background-color', '#f7f7f7'),\n",
    "                    ('padding', '5px')]},\n",
    "         {'selector': 'td',\n",
    "          'props': [('border', '1px solid black'),\n",
    "                    ('padding', '5px')]}]\n",
    "    )\n",
    "\n",
    "# Export to excel into our output folder\n",
    "styled_total.to_excel('../output/START_Data_Analysis.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4159618-2266-4c4a-a7af-dfde7ab9175e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race\n",
      "White                                        2980\n",
      "Black or African American                     994\n",
      "Unknown, not collected                        277\n",
      "Other: Hispanic                               191\n",
      "Asian                                         147\n",
      "                                             ... \n",
      "Other: Ecuadorian                               1\n",
      "Other: Pakistani                                1\n",
      "Other: Pakistani-Muslim                         1\n",
      "Other: White and Black or African America       1\n",
      "Other: mexican                                  1\n",
      "Name: count, Length: 162, dtype: int64\n",
      "Race\n",
      "White                                                0.597673\n",
      "Black or African American                            0.797032\n",
      "Unknown, not collected                               0.852587\n",
      "Other: Hispanic                                      0.890895\n",
      "Asian                                                0.920377\n",
      "Other                                                0.927597\n",
      "Black or African American, White                     0.933815\n",
      "Other: Latino                                        0.939430\n",
      "American Indian or Alaska Native                     0.944846\n",
      "Other: hispanic                                      0.948857\n",
      "Asian, White                                         0.952066\n",
      "Other: Mexican                                       0.954272\n",
      "Native Hawaiian or Other Pacific Islander            0.955876\n",
      "Unknown, not collected, White                        0.957481\n",
      "Other: Biracial                                      0.958885\n",
      "Other: Hispanic, White                               0.960088\n",
      "Other: Indian                                        0.961091\n",
      "Native Hawaiian or Other Pacific Islander, White     0.962094\n",
      "Other: Middle Eastern                                0.962896\n",
      "Black or African American, Unknown, not collected    0.963698\n",
      "American Indian or Alaska Native, White              0.964501\n",
      "Other: Latina                                        0.965303\n",
      "Other: Guyanese                                      0.966105\n",
      "Other: East Indian                                   0.966907\n",
      "Other: Bi-racial                                     0.967710\n",
      "Other: Mixed race                                    0.968311\n",
      "Other: Puerto Rican                                  0.968913\n",
      "Other: Filipino                                      0.969515\n",
      "Other: \"Hispanic\"                                    0.970116\n",
      "Other: Mixed Race                                    0.970718\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Getting race counts to normalize\n",
    "race_value_counts = sirs_demo.Race.value_counts()\n",
    "print(race_value_counts)\n",
    "\n",
    "race_norm = sirs_demo['Race'].value_counts(normalize = True)\n",
    "\n",
    "race_norm_cumsum = race_norm.cumsum().head(30)\n",
    "print(race_norm_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d05c653c-7672-406e-9acb-448bb6f742bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race_clean\n",
       "White                               3043\n",
       "Black/African American               994\n",
       "Other/Unknown                        491\n",
       "Hispanic/Latinx                      264\n",
       "Asian/Pacific Islander               167\n",
       "American Indian or Alaska Native      27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking top 96% of data\n",
    "sirs_demo['race_clean'] = sirs_demo['Race'].apply(categorize_race)\n",
    "sirs_demo.race_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61052ace-9c57-4e69-a918-57d4e70297ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sirs_merge = pd.merge(sirs_demo, sirs_abc, how = 'inner', left_on = 'Local ID', right_on = 'Local ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1da8af3a-fe35-4931-a37d-36a308b6796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19461, 53)\n",
      "(4986, 46)\n",
      "(26056, 8)\n"
     ]
    }
   ],
   "source": [
    "#printing df shape to make sure our merge was executed correctly\n",
    "print(sirs_merge.shape)\n",
    "print(sirs_demo.shape)\n",
    "print(sirs_abc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcff5128-37b8-4bb2-bf19-b34de45928fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sirs_merge.to_pickle('../data/sirs_demo_abc_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c454884-26db-4292-a089-4a9971941362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate Local ID values from the SIRS dataset\n",
    "sirs_demo_unique = sirs_demo.drop_duplicates(subset='Local ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e278be37-d662-437b-878a-77296b45d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4986, 46)\n",
      "(4986, 46)\n",
      "(1940, 57)\n"
     ]
    }
   ],
   "source": [
    "#printing df shape to make sure our drop was executed correctly\n",
    "\n",
    "print(sirs_demo_unique.shape)\n",
    "print(sirs_demo.shape)\n",
    "print(feis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7527e9b5-e47d-42c2-9bde-ddda47142b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets on 'Local ID'\n",
    "merged_data = pd.merge(sirs_demo_unique, feis, left_on='Local ID', right_on = 'Respondent ID #  (SIRS Local ID)', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfbb7829-5c30-4dcf-99e2-9cf263f4bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4986, 46)\n",
      "(4986, 46)\n",
      "(1940, 57)\n",
      "(1097, 103)\n"
     ]
    }
   ],
   "source": [
    "#printing df shape to make sure our merge was executed correctly\n",
    "\n",
    "print(sirs_demo_unique.shape)\n",
    "print(sirs_demo.shape)\n",
    "print(feis.shape)\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eacea62e-2869-47d5-949f-5fa3c8ac6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_pickle('../data/feis_sirs_demo_merged')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
